---
title: "Data Science Programming - Wine Dataset"
author: "Sujith Bysani Santhosh-20MID0180"
date: "`r Sys.Date()`"
output:
  html_document: default

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
```
## AIM:
 To evaluate and compare 2 different classification models on Wine prediction dataset from the UCI dataset library.

## LITERATURE ANALYSIS:
<table border=1 cellpadding=6>
	<tr>
		<td bgcolor="#DDEEFF"><p class="normal"><b>Data Set Characteristics:&nbsp;&nbsp;</b></p></td>
		<td><p class="normal">Multivariate</p></td>
		<td bgcolor="#DDEEFF"><p class="normal"><b>Number of Instances:</b></p></td>
		<td><p class="normal">178</p></td>
		<td bgcolor="#DDEEFF"><p class="normal"><b>Area:</b></p></td>
		<td><p class="normal">Physical</p></td>
	</tr>

	<tr>
		<td bgcolor="#DDEEFF"><p class="normal"><b>Attribute Characteristics:</b></p></td>
		<td><p class="normal">Integer, Real</p></td>
		<td bgcolor="#DDEEFF"><p class="normal"><b>Number of Attributes:</b></p></td>
		<td><p class="normal">13</p></td>
		<td bgcolor="#DDEEFF"><p class="normal"><b>Date Donated</b></p></td>
		<td><p class="normal">1991-07-01</p></td>
	</tr>
	<tr>
		<td bgcolor="#DDEEFF"><p class="normal"><b>Associated Tasks:</b></p></td>
		<td><p class="normal">Classification</p></td>
		<td bgcolor="#DDEEFF"><p class="normal"><b>Missing Values?</b></p></td>
		<td><p class="normal">No</p></td>
		<td bgcolor="#DDEEFF"><p class="normal"><b>Number of Web Hits:</b></p></td>
		<td><p class="normal">2044123</p></td>
	</tr>
	<!--
	<tr>

		<td bgcolor="#DDEEFF"><p class="normal"><b>Highest Percentage Achieved:&nbsp;&nbsp;</b></p></td>
		<td><p class="normal">100%</p></td>
	</tr>
	-->
</table>
<br>

These data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines.

I think that the initial data set had around 30 variables, but for some reason I only have the 13 dimensional version. I had a list of what the 30 or so variables were, but a.) I lost it, and b.), I would not know which 13 variables are included in the set.

The attributes are: <br>
1) Alcohol <br>
2) Malic acid <br>
3) Ash <br>
4) Alcalinity of ash  <br>
5) Magnesium  <br>
6) Total phenols  <br>
7) Flavanoids <br>
8) Nonflavanoid phenols <br>
9) Proanthocyanins <br>
10)Color intensity <br>
11)Hue <br>
12)OD280/OD315 of diluted wines <br>
13)Proline <br>

In a classification context, this is a well posed problem with "well behaved" class structures. A good data set for first testing of a new classifier, but not very challenging.



## Wine Dataset



```{r dataset}
setwd("E://sujith//vit files//3-1//DSP")
dataset=read.csv("wine.csv")
head(dataset)
```
```{r}
str(dataset)
```
## VISUALIZING THE DATA:
The following graph explains how the dataset is correlated to one other:
```{r}
pairs(dataset)
```

##  ANALYSIS OF DATA USING VISUALIZATION

This is a histogram that gives the occurrences of the "output":
```{r}
ggplot(data=dataset,aes(x=Output,fill=as.factor(Output)))+geom_histogram()+ labs(title = "B.S.SUJITH 20MID0180")
```

This is a density plot that tells us again about the Output Factor visually:
```{r}
ggplot(data=dataset,aes(x=Output,fill=as.factor(Output)))+geom_density(alpha=0.4)+ labs(title = "B.S.SUJITH 20MID0180")
```

This is a box-plot that generates a graph between Output and Alcohol factors in the data set:
```{r}
ggplot(data=dataset,aes(x=as.factor(Output),y=Alcohol))+geom_boxplot()+labs(title = "B.S.SUJITH 20MID0180")
```
This is a line bar that generates a graph between Alcohol and Proline from our dataset:
```{r}
ggplot(data=dataset,aes(x=Alcohol,y=Proline))+geom_line()+ labs(title = "B.S.SUJITH 20MID0180")
```
Now we make a scatterplot between Proline , Alcohol and Output factors of our dataset :
```{r}
ggplot(data = dataset,aes(x=Proline,y=Alcohol,color=Output))+geom_point(alpha=0.4,size=3)+ labs(title = "B.S.SUJITH 20MID0180")
```
This is a Histogram that consist various columns of our dataset :
```{r}
ggplot(dataset, aes(x = Alcohol)) + geom_histogram(fill = "cornflowerblue", color = "white") + facet_wrap(~Output, ncol = 1)+ labs(title = "B.S.SUJITH 20MID0180")


```
<h1> ALGORITHM -1 : DECISION TREE ANALYSIS </h1>
We will first split the data :
```{r}
library(caTools)
set.seed(123)
split=sample.split(Y=dataset$Output,SplitRatio = 2/3)
train_set=subset(x=dataset,split==TRUE)
test_set=subset(x=dataset,split==FALSE)

```
We Create a model now :
```{r}
library(rpart)
fit=rpart(formula=Output~.,data=train_set,method="class")
```
Now Predict the data:
```{r}
predict_unseen=predict(object=fit,newdata=test_set,type="class")
```
Let's Create confusion matrix and check accuracy :
```{r}
cm=table(test_set$Output,predict_unseen)
cm
sum(diag(cm))/sum(cm)

```
## ALGORITHM -2 : NAIVE BAYES ALGORITHM 
We shall first train the classifier using naiveBayes() method in 'e1071' package
```{r}
library(e1071)
classifier = naiveBayes(Output~., data =
                          train_set)
summary(classifier)
```
To test the accuracy of this classifier, letâ€™s create a confusion matrix containing predicted values from the classifier and the actual values from the data set itself.
```{r}

cm = table(predict(classifier,dataset[,-1]),dataset[,1],dnn=list("predicted","actual"))
cm
```
The accuracy of this model is as follows :
```{r}
accuracy = sum(diag(cm)) / sum(cm)
accuracy
```
## COMPARATIVE STATEMENT:
The accuracy of Naive-Bayes is 0.96621 and the accuracy of Decision tree algorithm is 0.90

## RESULT:
Decision tree algorithm has better prediction analysis than Naive-Bayes 